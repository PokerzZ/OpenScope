"""Batch OpenDigger dataset generation utilities."""

import os
from typing import Dict, List

import pandas as pd
from getdata import OpenPuppeteerDataCore
from tqdm import tqdm

# å®šä¹‰æ•°æ®é›†ä¿å­˜è·¯å¾„
# è·¯å¾„: ChatDev/puppeteer/data/OpenDigger
DATASET_ROOT = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "puppeteer", "data", "OpenDigger")
TRAIN_DIR = os.path.join(DATASET_ROOT, "train")
TEST_DIR = os.path.join(DATASET_ROOT, "test")
CONTEXT_SUFFIX = "_context.csv"

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(TEST_DIR, exist_ok=True)

# ä»“åº“åˆ—è¡¨ (Repo List)
# åŒ…å«ä¸åŒç±»å‹çš„é¡¹ç›®ä»¥ä¿è¯æ•°æ®å¤šæ ·æ€§ï¼šæˆç†ŸæœŸã€æˆé•¿æœŸã€ç¨³å®šæœŸç­‰
REPOS: Dict[str, List[str]] = {
    "train": [
        "X-lab2017/open-digger",
        "pytorch/pytorch",
        "tensorflow/tensorflow",
        "kubernetes/kubernetes",
        "microsoft/vscode",
        "apache/echarts",
        "ant-design/ant-design",
        "vuejs/core",
        "facebook/react",
        "twbs/bootstrap",
        "golang/go",
        "rust-lang/rust"
    ],
    "test": [
        "langchain-ai/langchain",
        "Significant-Gravitas/AutoGPT",
        "huggingface/transformers",
        "django/django",
        "flask/flask"
    ]
}

def safe_repo_name(repo: str) -> str:
    """Convert a repo slug into a filesystem-safe name."""
    return repo.replace("/", "_")

def batch_process() -> None:
    """Fetch OpenDigger metrics for train/test repo lists."""
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡æ„å»ºæ•°æ®é›†...")
    print(f"ğŸ“‚ æ•°æ®å°†ä¿å­˜è‡³: {DATASET_ROOT}")
    
    try:
        core = OpenPuppeteerDataCore()
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ– OpenPuppeteerDataCore å¤±è´¥: {e}")
        return

    for split, repo_list in REPOS.items():
        save_dir = TRAIN_DIR if split == "train" else TEST_DIR
        saved_count = 0
        print(f"\nProcessing {split} set ({len(repo_list)} repos)...")
        
        for repo in tqdm(repo_list, desc=f"{split} repos"):
            try:
                # print(f"Fetching {repo}...")
                df = core.build_aligned_dataset(repo)
                
                if df is not None and not df.empty:
                    # ä¿å­˜ä¸º CSV
                    safe_name = safe_repo_name(repo)
                    file_path = os.path.join(save_dir, f"{safe_name}{CONTEXT_SUFFIX}")
                    df.to_csv(file_path, index=False)
                    saved_count += 1
                else:
                    print(f"âš ï¸ No data found for {repo}")
            except Exception as e:
                print(f"âŒ Error processing {repo}: {e}")

        print(f"âœ… Saved {saved_count} datasets for {split}")

    print("\nâœ¨ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"è®­ç»ƒé›†è·¯å¾„: {TRAIN_DIR}")
    print(f"æµ‹è¯•é›†è·¯å¾„: {TEST_DIR}")

if __name__ == "__main__":
    batch_process()
